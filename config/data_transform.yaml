# 任务配置
task_name: data_transform
description: Transform Alpaca format dataset to structured prompt format

# OpenAI配置
openai:
  model_name: "deepseek-reasoner"
  max_tokens: 8192
  temperature: 0.7
  api_key: "sk-cUaGu4E02RDTCxnnC3398860D5944953A4Fa9c5dA13aF93e"
  api_base: "http://35.198.249.220:7220/v1"
  pricing:
    input_price_per_million: 1.0  # 每百万tokens的输入价格
    output_price_per_million: 2.0  # 每百万tokens的输出价格
    currency: "CNY"  # 货币单位

# 并发配置
concurrency:
  max_concurrent_requests: 200  # 高速模式
  batch_size: 200  # 高速模式批量
  request_timeout: 60
  max_retries: 3
  retry_delay: 1

# 速率限制
rate_limits:
  tokens_per_minute: 200000
  requests_per_minute: 2000

# 数据集配置
datasets:
  - name: "HuggingFaceH4/MATH-500"  # 数据集名称
    config: ""  # 数据集配置名称
    split: "train"  # 数据集分片
    subset: ""  # 数据集子集
    num_samples: 5  # 加载的样本数量，-1表示全部加载
    field_mapping:  # 字段映射配置
      instruction: "problem"
      input: ""
      output: "solution"

  # - name: "xDAN2099/xDAN-Agentic-Chat-v1-alpaca-ds-v3-cleaned-v0-part2"
  #   config: ""
  #   split: "train"
  #   subset: ""
  #   num_samples: -1  # 处理全部数据
  #   field_mapping:
  #     instruction: "instruction"
  #     input: "input"
  #     output: "output"
# 数据集通用配置
dataset_common:
  hf_cache_dir: "~/.cache/huggingface/datasets"
  shuffle_seed: 42
  combine_datasets: true

# 转换配置
transform:
  validate_input: true
  required_fields:  # 必需字段
    - instruction
    - output
  optional_fields:  # 可选字段
    - input
  prompt_template: "direct_refined_answer"  # 使用的prompt模板名称
  prompt_templates:
    structured_analysis:  # 结构化分析模板
      path: "prompt/transformation/structured_analysis.md"
      description: "将问答对转换为结构化的分析格式，包含分析、解决、验证和最终答案四个部分"
    direct_refined_answer:  # 简洁回答模板
      path: "prompt/transformation/direct_refined_answer.md"
      description: "生成简洁明了的回答，直接针对问题要点"
    long_cot:  # 详细的Chain-of-Thought分析模板
      path: "prompt/transformation/long_cot_shot_en.md"
      description: "使用详细的Chain-of-Thought方法进行深入分析和回答，适合复杂问题"

# 输出配置
output:
  base_dir: "output"  # 基础输出目录
  save_local: true  # 同时保存到本地
  save_interval: 1000  # 每1000条数据保存一次分段JSON
  push_interval: 5000  # 每5000条数据推送一次到hub
  push_to_hub: true  # 启用推送到hub
  hub_config:
    owner: "xDAN2099"  # Hugging Face Hub 用户名/组织名
    repo_prefix: "xDAN"  # 仓库名前缀
    split: "train"  # 数据集分割
    token: "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"  # Hugging Face Hub token
  save_format: "json"  # 支持: json, jsonl, parquet
  include_metadata: true
  file_naming:
    include_timestamp: true  # 是否包含时间戳

# 日志配置
logging:
  level: "INFO"
  save_path: "logs"
  file_name: "processing.log"