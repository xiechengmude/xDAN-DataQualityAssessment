# 任务配置
task_name: data_transform
description: Transform Alpaca format dataset to structured prompt format

# 输入配置
input:
  format: alpaca
  fields:
    - instruction
    - input
    - output
  dataset:
    name: "xDAN2099/xDAN-Agentic-Chat-v1-alpaca-ds-v3-cleaned-v0-part2"
    config: ""
    split: "train"
    subset: ""
    num_samples: 50  # 测试用50条数据

# OpenAI配置
openai:
  model_name: "deepseek-chat"
  max_tokens: 8192
  temperature: 0.7
  api_key: "sk-cUaGu4E02RDTCxnnC3398860D5944953A4Fa9c5dA13aF93e"
  api_base: "http://35.240.173.116:7220/v1"
  pricing:
    input_price_per_million: 1.0  # 每百万tokens的输入价格
    output_price_per_million: 2.0  # 每百万tokens的输出价格
    currency: "CNY"  # 货币单位

# 并发配置
concurrency:
  max_concurrent_requests: 5  # 小规模测试用5并发
  batch_size: 5  # 小规模测试用5批量
  request_timeout: 60
  max_retries: 3
  retry_delay: 1

# 速率限制
rate_limits:
  tokens_per_minute: 200000
  requests_per_minute: 2000

# 数据集配置
datasets:
  - name: "xDAN2099/xDAN-Agentic-Chat-v1-alpaca-ds-v3-cleaned-v0-part2"
    config: ""
    split: "train"
    subset: ""
    num_samples: -1  # 恢复到处理全部数据
    field_mapping:
      instruction: "instruction"
      input: "input"
      output: "output"

# 数据集通用配置
dataset_common:
  hf_cache_dir: "~/.cache/huggingface/datasets"
  shuffle_seed: 42
  combine_datasets: true

# 转换配置
transform:
  validate_input: true
  required_fields:  # 必需字段
    - instruction
    - output
  optional_fields:  # 可选字段
    - input
  prompt_template: "long_cot"  # 使用的prompt模板名称
  prompt_templates:
    structured_analysis:  # 结构化分析模板
      path: "prompt/transformation/structured_analysis.md"
      description: "将问答对转换为结构化的分析格式，包含分析、解决、验证和最终答案四个部分"
    concise_answer:  # 简洁回答模板
      path: "prompt/transformation/concise_answer.md"
      description: "生成简洁明了的回答，直接针对问题要点"
    long_cot:  # 详细的Chain-of-Thought分析模板
      path: "prompt/transformation/long_cot.md"
      description: "使用详细的Chain-of-Thought方法进行深入分析和回答，适合复杂问题"

# 输出配置
output:
  base_dir: "output"  # 基础输出目录
  save_local: true  # 同时保存到本地
  save_interval: 5  # 每5条数据保存一次分段JSON
  push_interval: 20  # 每20条数据推送一次到hub
  push_to_hub: true  # 启用推送到hub
  hub_config:
    owner: "xDAN2099"  # Hugging Face Hub 用户名/组织名
    repo_prefix: "xDAN"  # 仓库名前缀
    split: "train"  # 数据集分割
    token: "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"  # Hugging Face Hub token
  save_format: "json"  # 支持: json, jsonl, parquet
  include_metadata: true
  file_naming:
    include_timestamp: true  # 是否包含时间戳

# 日志配置
logging:
  level: "INFO"
  save_path: "logs"
  file_name: "processing.log"